{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_report = \"world_happiness_report_2019_original_file.csv\"\n",
    "region=\"Country-names-with-region.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_report_df = pd.read_csv(happiness_report)\n",
    "region_df=pd.read_csv(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happiness_report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_df=happiness_report_df.merge(region_df, on='Country name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_df[['Country name', 'Region', 'Year', 'Life Ladder', 'Log GDP per capita',\n",
    "       'Social support', 'Healthy life expectancy at birth',\n",
    "       'Freedom to make life choices', 'Generosity',\n",
    "       'Perceptions of corruption', 'Positive affect', 'Negative affect',\n",
    "       'Confidence in national government', 'Democratic Quality',\n",
    "       'Delivery Quality', 'Standard deviation of ladder by country-year',\n",
    "       'Standard deviation/Mean of ladder by country-year',\n",
    "       'GINI index (World Bank estimate)',\n",
    "       'GINI index (World Bank estimate), average 2000-16',\n",
    "       'gini of household income reported in Gallup, by wp5-year',\n",
    "       'Most people can be trusted, Gallup',\n",
    "       'Most people can be trusted, WVS round 1981-1984',\n",
    "       'Most people can be trusted, WVS round 1989-1993',\n",
    "       'Most people can be trusted, WVS round 1994-1998',\n",
    "       'Most people can be trusted, WVS round 1999-2004',\n",
    "       'Most people can be trusted, WVS round 2005-2009',\n",
    "       'Most people can be trusted, WVS round 2010-2014']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df = happiness_df[['Country name', 'Region', 'Year', 'Life Ladder', 'Log GDP per capita',\n",
    "       'Social support', 'Healthy life expectancy at birth',\n",
    "       'Freedom to make life choices', 'Generosity',\n",
    "       'Perceptions of corruption', 'Positive affect', 'Negative affect',\n",
    "       'Confidence in national government', 'Democratic Quality',\n",
    "       'Delivery Quality', 'Standard deviation of ladder by country-year',\n",
    "       'Standard deviation/Mean of ladder by country-year',\n",
    "       'GINI index (World Bank estimate)','gini of household income reported in Gallup, by wp5-year',\n",
    "       'Most people can be trusted, Gallup']]\n",
    "happy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df= happy_df.rename(columns={'Life Ladder':'Happiness_Score', 'Log GDP per capita':'GDP', 'Freedom to make life choices':'Freedom'})\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = report_df.apply (pd.to_numeric, errors='coerce')\n",
    "df = report_df.dropna()\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.groupby('Region')['Happiness_Score','GDP'].mean().sort_values(by=\"Happiness_Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df):\n",
    "    plt.figure(figsize=(14,12))\n",
    "    sns.heatmap(df.corr(), center=0, annot=True, cmap=\"RdBu_r\", linewidths = .5, fmt='.2f',annot_kws={'size': 10})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(df)\n",
    "plt.savefig(\"correlations.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we prepare the data to use a model\n",
    "df1 = df.drop([\"Country name\",\"Region\"], axis=1)\n",
    "y = df1[\"Happiness_Score\"]\n",
    "X = df1.drop([\"Happiness_Score\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in X.columns.values.tolist():\n",
    "    X = df1.drop([\"Happiness_Score\"], axis=1)\n",
    "    X = X[feature]\n",
    "    X = X.values.reshape(-1,1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    plt.title(\"Regressions of \" + feature)\n",
    "    plt.scatter(X, y)\n",
    "\n",
    "    degrees = [1,2,3,4]\n",
    "    for degree in degrees:\n",
    "        poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "        # transforms the existing features to higher degree features.\n",
    "        X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "        # fit the transformed features to Linear Regression\n",
    "        poly_model = LinearRegression()\n",
    "        poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "        # predicting on test data-set\n",
    "        y_test_predict = poly_model.predict(poly_features.fit_transform(X_test))\n",
    "\n",
    "        # Plotting the regression\n",
    "\n",
    "        new_x, new_y = zip(*sorted(zip(X_test, y_test_predict)))\n",
    "        plt.plot(new_x, new_y, label=\"Degree = \" + str(degree))\n",
    "\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"Happiness_Score\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"start.svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots can show us how adjusted are the regressions with the data using only an indicator each time. Now we will try to use all the columns to predict the happiness score, but if we want to plot the regression result line we will need to perform a PCA to the data.\n",
    "\n",
    "Applying PCA to our data we will obtain a single “feature” that will allow us to represent all the attribute columns in a single axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# First we prepare the data to use a model\n",
    "reg_data = df.drop([\"Country name\",\"Region\"], axis=1)\n",
    "y = reg_data[\"Happiness_Score\"]\n",
    "X = reg_data.drop([\"Happiness_Score\"], axis=1)\n",
    "\n",
    "# Normalisation and PCA\n",
    "X_norm = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.33, random_state=42)\n",
    "\n",
    "plt.scatter(X_pca, y)\n",
    "\n",
    "degrees = [1,2,3,4]\n",
    "for degree in degrees:\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "    # transforms the existing features to higher degree features.\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # fit the transformed features to Linear Regression\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # predicting on test data-set\n",
    "    y_test_predict = poly_model.predict(poly_features.fit_transform(X_test))\n",
    "\n",
    "    # Plotting the regression\n",
    "    new_x, new_y = zip(*sorted(zip(X_test, y_test_predict)))\n",
    "    plt.plot(new_x, new_y, label=\"Degree = \" + str(degree))\n",
    "    plt.xlabel(\"Principal Component\")\n",
    "    plt.ylabel(\"Happiness_Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"PCA.svg\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model on test dataset\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_predict))\n",
    "r2_test = r2_score(y_test, y_test_predict)\n",
    "print(\"RMSE test (PCA): \" + str(rmse_test))\n",
    "print(\"R2square test (PCA): \" + str(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rsquare is the proportion of the variance in the dependent variable that is predictable from the independent variable. Basically it says how good the regression function is fitting the data. The value goes between 0 and 1, being 1 the best value and 0 the worst.\n",
    "\n",
    "RMSE is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talking about the performance of the regression models, the R-square of the showed models keeps around a 0.7 value. By looking at the distribution of the data on the previous charts, it can be observed that the regression functions are fitting the data properly.\n",
    "\n",
    "There are difficult data distributions for a regression model to fit, as for example the one observed in the PCA chart. The more high the degree of the regression polynomial, the better fitted the data. Nonetheless, the increase of the degree of the model can cause overfitting, so this is an aspect that has to be treated carefully to build a correct regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
